{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4376  230 4457 ...,  802 1663 3773]\n",
      " [4591 4465 2166 ..., 1550 3240 1802]\n",
      " [4398  180 2387 ...,  374 2042  177]\n",
      " ..., \n",
      " [1329 1603 2425 ...,  165 1285 3199]\n",
      " [2740  458 3028 ...,  428 4148 1268]\n",
      " [3094 1507 1930 ..., 3374 1247 4826]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = (X - np.average(X, axis=0))\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1881.804 -2241.914  1969.188 ..., -1699.224  -823.309  1260.795]\n",
      " [ 2096.804  1993.086  -321.812 ...,  -951.224   753.691  -710.205]\n",
      " [ 1903.804 -2291.914  -100.812 ..., -2127.224  -444.309 -2335.205]\n",
      " ..., \n",
      " [-1165.196  -868.914   -62.812 ..., -2336.224 -1201.309   686.795]\n",
      " [  245.804 -2013.914   540.188 ..., -2073.224  1661.691 -1244.205]\n",
      " [  599.804  -964.914  -557.812 ...,   872.776 -1239.309  2313.795]]\n",
      "(1000, 20)\n",
      "[ 1431.77172607  1428.42487748  1409.64494418  1441.72913267  1425.30632634\n",
      "  1452.78602856  1463.27470848  1425.61814187  1464.23714827  1450.52552159\n",
      "  1460.48026942  1409.56051738  1456.71243641  1460.95500543  1460.42127453\n",
      "  1440.69742067  1436.30217949  1416.84593581  1436.75612388  1413.43350709]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols)\n",
    "print(np.shape(ave_cols))\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31431845 -1.56950081  1.396939   ..., -1.19930047 -0.57303323\n",
      "   0.89200871]\n",
      " [ 1.46448206  1.39530334 -0.22829295 ..., -0.67136728  0.52457824\n",
      "  -0.50246792]\n",
      " [ 1.32968403 -1.6045044  -0.07151588 ..., -1.50137989 -0.30924455\n",
      "  -1.65215059]\n",
      " ..., \n",
      " [-0.81381409 -0.6083022  -0.04455874 ..., -1.64889064 -0.8361259\n",
      "   0.48590542]\n",
      " [ 0.17167821 -1.40988443  0.38320855 ..., -1.46326707  1.15655745\n",
      "  -0.88027133]\n",
      " [ 0.41892432 -0.6755091  -0.39571099 ...,  0.61599923 -0.86257436\n",
      "   1.63700308]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (ave_cols / std_cols)\n",
    "print(X_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.15143483426e-18\n",
      "-1.79208648162\n",
      "1.79953596824\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(np.average(X_norm))\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.average(X_norm.min()))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.average(X_norm.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, 4, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[643 589 545 506 960 724  25 191 512 803 561 391 309 603 674 672   8 742\n",
      " 424 502 538 352 924 790 501 344 478 207 485 350 780  43 154 196 921 933\n",
      " 829 297 666 413 636 178 901 830 739 470 223  18  35 101  96 359 558 115\n",
      " 833 712  30 388 887 493 854 100 484  52 377 667 282 164  55 392 488 182\n",
      " 386 732 945 620 686  72 246 828 360 814 774 801 356 163 375 108 632 970\n",
      " 734 294 247 564 508 703 137 567 519 928  20 795 728 998 134 188 231 452\n",
      " 940 587 851 765 118 474 775  39 979 326 292 678 367 583 136 971 245  94\n",
      " 781 290 633 855 177 748  76 649 715  16   9 250  67 850 898 111 978 248\n",
      " 242  21 565 165 711 368 396  80  36 529 963 274 899 697 808 726 157  23\n",
      " 418 676 738 543 103 605 148 362 379 285 466 444 604 407 594 503 848 334\n",
      " 658 454 891 394 644 254 301 877 707 526 357 817 747 929 465 366 783 784\n",
      " 339 975  24 219 354 405 787 263 480   1 341 121 126 284 832 626 450 618\n",
      " 490  95 948 129 369 577 878 651 560 602 646 143 427 264 380 881 180 601\n",
      " 173 510 361 302 653 957 288 805 327 804 754 110 308 494 719 665 965 187\n",
      " 769 616 355 431 621 267  34 448 198 186 464 457 690 119 799 144 373 299\n",
      " 869 533 908  40 771 304 202 271 669 557 988 684  17 268 305 825 987 758\n",
      " 106 638 642 927 932 215 415 156 318 174 639 753 730  31 439 158 516  83\n",
      " 204 208 663 181 554 166 820  26 652 996  63 772 857 358 393 629  49 307\n",
      " 390 614 122 794 425 505 954 432 217 145 654 888  13 176 931 995 151 138\n",
      " 185 731 721 693 471 612 270 949 751 446 903 729 551 461  46 810 701 696\n",
      "  12 964 991 688 150 757 159 419  82 631  73 755 809 216 634 625 266 863\n",
      " 745 785 483 249 552 371 683 909 376 142 648 952 555 411 870  60 500 513\n",
      " 897  54 495  98 980 397 400 735 896 201 456 197 120 944 746 541 623 507\n",
      " 149 559  89 260 981 595 348 922 491  29 776 997 917 346  71 895 141 168\n",
      " 412 581 793 713 477 313 220 343  66 836 329 789 107 930 462 624 443 759\n",
      " 265 345 910 788 831 607 841 289 133 243 846 662 518 911 913 240 229 890\n",
      " 596 104 381 436 382 786 720 514 906 999 226  42 135 440 209 169 273 105\n",
      " 420 973 234  32 437 871 819 613 189 609 619 955 556 286 467 319 816 611\n",
      " 228 323 152 718 277 404 203 925  48 598 679 192 241 147 733  11 544 328\n",
      " 661 972 349 278 962 578 540 403 692 205 256 153 330 586 312 856 582 591\n",
      " 162 235 967  59 873 575 710 398 295 562 839 395 441 706 351 492 498 685\n",
      " 459 347 763 262 822 322 640 363 951 907 447 675 421 296 867 102 770 645\n",
      " 579 714 976  56 824 303 802 597 983 517 389 408 365 989 445  38 374 694\n",
      " 717 280  75 705 524 232 864 918 699  90 821  69 673 383 139 426 402 671\n",
      " 409 287 479 736 884  15  65 845 489 939 321 900 842 336 453 761 969 469\n",
      " 127 114 986 650 815 438 968 372 698 401 497 628 532 966 132 214 752 858\n",
      " 574 422  85  86 370  79 476 722 708 291 130 993 332 902  27 342 570 175\n",
      "  91 704 528 414 112   6 125 813 659 475 630 167 259 468 610  70 778 749\n",
      " 224 563 255 760 622 865  53 320 170 378 647 615 384 238 935 117 584  84\n",
      " 823 253 435 919 880 504 992 442 641 218 915 549  51 233 779  93  62 792\n",
      " 889 740 225 796 340 767 222 315 844 527 700 806 882 486   4 417 773 317\n",
      "  45 573 837 727 257 364 300 872 852 416 723 473 571 893 990 682 689 279\n",
      " 525 756 298  88  28 239 861  74 938 190 212 539  68 961  99 600 569 487\n",
      " 179 664 764 576   2 530 261 496 211 926 946 668 160 547 387 943 283 635\n",
      " 953 853  44  14  33  19 537 434   3  22  37 655 800 499  61 546 430 677\n",
      " 590 798 515 958 155   5 768 606  50 835   7 472  81 766 599 221 429 311\n",
      " 834 324 482 281 883 826 269 406 695 511 956 449 941 325 737 568 252 860\n",
      " 258 210 936 337 521 542 124  92 199 213 460 782 670 423 916 193 617 123\n",
      " 335  97 942 548 868 399 905 131 316   0 797 200 702 244 862 812 338  64\n",
      " 536 272 716 885 879 227 894  57 691 681  58 977  47 777 914 113 194 937\n",
      " 509 140 128 455 984 531 275 741 116 161 892 827 593 847 840 251 195 172\n",
      " 750 276 725 522 550 791 331 310 875 994 592 314 876 230 886 920 974 743\n",
      " 184 982 744 811 874 947 588 306 637 807 523 572 866 463 923 657 428 236\n",
      "  87 535 580 985 385  78 627 206 433 293  41 660 959 520 709 608 109 183\n",
      "  10 950 859 843 687 904 237 912 566 171 849 934 656 481 585 458 353  77\n",
      " 451 333 838 410 818 762 146 534 553 680]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(len(X_norm))\n",
    "print(row_indices)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "# 0 - 60%\n",
    "num_first_sixty_pct_rows = int(0.60 * len(row_indices))\n",
    "first_sixty_pct_rows = row_indices[:num_first_sixty_pct_rows]\n",
    "\n",
    "# 60% - 80% pct\n",
    "num_twenty_pct_rows = int(0.20  * len(row_indices))\n",
    "mid_twenty_pct_rows = row_indices[num_first_sixty_pct_rows:(num_first_sixty_pct_rows + num_twenty_pct_rows)]\n",
    "\n",
    "# last 20%\n",
    "last_twenty_pct_rows = row_indices[(num_first_sixty_pct_rows + num_twenty_pct_rows):]\n",
    "#print(len(last_twenty_pct_rows))\n",
    "    \n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Create a Training Set\n",
    "Y = row_indices[:num_first_sixty_pct_rows]\n",
    "#print(Y)\n",
    "#print(len(Y))\n",
    "\n",
    "X_train = X_norm[first_sixty_pct_rows]\n",
    "#print(X_train)\n",
    "#print(len(X_train))\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[mid_twenty_pct_rows]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[last_twenty_pct_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(np.shape(X_train))\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(np.shape(X_crossVal))\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37729199  0.08686911  1.68566419  0.73383965  0.97024055 -1.18063842\n",
      "   0.05344929 -0.89914049  0.34878503 -0.96192861 -0.25671829  1.03955522\n",
      "  -0.85517221 -1.00211574 -0.10389468 -0.06733406 -0.5331037   0.35556159\n",
      "   0.65682059 -0.70339708]\n",
      " [-1.52551972 -0.58870019  1.72113411 -0.59095844  1.21299539  0.60007805\n",
      "  -0.15225371 -1.54096734  0.28322188 -1.23769074  0.10549133  0.34785027\n",
      "  -1.20390268  0.26281028 -1.58291997 -0.48102259 -0.48227874 -1.21271054\n",
      "  -1.64906831 -0.6991521 ]\n",
      " [ 0.42171806 -0.14765495 -0.82844407 -0.07699227 -1.2054321  -0.58729571\n",
      "  -0.17412247  1.6709727   1.47770052  0.82225234  1.00519537 -1.21575766\n",
      "  -0.8435021   0.86789394  0.73285018 -0.58999759 -0.21701422  0.54683151\n",
      "   0.19327636  0.27436381]\n",
      " [ 0.29041222 -1.2964728  -0.3467625  -0.10612396 -1.70357063 -0.45444751\n",
      "  -0.31900299 -0.33236881 -0.28567504 -0.67927243 -0.98524576  0.42517933\n",
      "   0.48277202 -0.90081214  1.04577359  1.42846927  1.36482561  0.56165316\n",
      "  -0.89598296 -1.5778634 ]\n",
      " [-0.77400327 -1.4728909   0.93299239 -0.80181636  0.62785801  0.8017595\n",
      "  -1.34820139 -1.75210383 -0.76169082 -0.908155   -0.16291353  0.27335896\n",
      "  -1.48329893  1.53389666 -0.01487927 -0.58999759  1.68857364  0.80585755\n",
      "   0.50091382 -1.27717717]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
